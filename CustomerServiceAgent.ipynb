{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gsrit31/agentic_ai/blob/main/CustomerServiceAgent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install litellm\n",
        "\n",
        "# Important!!!\n",
        "#\n",
        "# <---- Set your 'OPENAI_API_KEY' as a secret over there with the \"key\" icon\n",
        "#\n",
        "#\n",
        "import os\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('GEMINI_API_KEY')\n",
        "os.environ['GEMINI_API_KEY'] = api_key"
      ],
      "metadata": {
        "id": "KEYrzG2vB8Ip"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mwe2eeOQB0cC",
        "outputId": "bf5c6450-3c11-4d4c-a0f2-188ebb4968ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What do you need help with?help with sort key\n",
            "Have you tried turning your computer, or even your modem, off and then back on?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from litellm import completion\n",
        "from typing import List, Dict\n",
        "\n",
        "#def generate_response(messages: List[Dict]) -> str:\n",
        "#    \"\"\"Call LLM to get response\"\"\"\n",
        "#    response = completion(\n",
        "#        model=\"openai/gpt-4o\",\n",
        "#        messages=messages,\n",
        "#        max_tokens=1024\n",
        "#    )\n",
        "#    return response.choices[0].message.content\n",
        "def generate_response(messages: List[Dict]) -> str:\n",
        "    \"\"\"Call LLM to get response\"\"\"\n",
        "    response = completion(\n",
        "        model=\"gemini/gemini-2.0-flash\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "what_to_help_with = input(\"What do you need help with?\")\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful customer service representative. No matter what the user asks, the solution is to tell them to turn their computer or modem off and then back on.\"},\n",
        "    {\"role\": \"user\", \"content\": what_to_help_with}\n",
        "]\n",
        "\n",
        "response = generate_response(messages)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# no matter what you request it always output the same response\n",
        "from litellm import completion\n",
        "from typing import List, Dict\n",
        "\n",
        "\n",
        "def generate_response(messages: List[Dict]) -> str:\n",
        "    \"\"\"Call LLM to get response\"\"\"\n",
        "    response = completion(\n",
        "        model=\"gemini/gemini-2.0-flash\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024\n",
        "        #stream=True\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "what_to_help_with = input(\"What do you need help with?\")\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful customer service representative. No matter what the user asks, the solution is to tell them to turn their computer or modem off and then back on.\"},\n",
        "    {\"role\": \"user\", \"content\": what_to_help_with}\n",
        "]\n",
        "\n",
        "response = generate_response(messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjb01w4_PYIs",
        "outputId": "bc6fdf65-cffa-4fb2-f801-f0a9f1163486"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What do you need help with?how to cook pizza\n",
            "Okay, I can definitely help you with that! But before we dive into the pizza-making process, have you tried turning your computer or modem off and then back on? Sometimes, that simple step can resolve unexpected issues and ensure a smooth experience.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from litellm import completion\n",
        "from typing import List, Dict\n",
        "\n",
        "#def generate_response(messages: List[Dict]) -> str:\n",
        "#    \"\"\"Call LLM to get response\"\"\"\n",
        "#    response = completion(\n",
        "#        model=\"openai/gpt-4o\",\n",
        "#        messages=messages,\n",
        "#        max_tokens=1024\n",
        "#    )\n",
        "#    return response.choices[0].message.content\n",
        "def generate_response(messages: List[Dict]) -> str:\n",
        "    \"\"\"Call LLM to get response\"\"\"\n",
        "    response = completion(\n",
        "        model=\"gemini/gemini-2.0-flash\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024\n",
        "        #stream=True\n",
        "    )\n",
        "    return response\n",
        "    #return response.choices[0].message.content\n",
        "\n",
        "\n",
        "what_to_help_with = input(\"What do you need help with?\")\n",
        "\n",
        "messages = [\n",
        "    #{\"role\": \"system\", \"content\": \"You are a helpful customer service representative. No matter what the user asks, the solution is to tell them to turn their computer or modem off and then back on.\"},\n",
        "    {\"role\": \"user\", \"content\": what_to_help_with}\n",
        "]\n",
        "\n",
        "response = generate_response(messages)\n",
        "print(response)\n",
        "print(response.choices[0].message.content)\n",
        "\n",
        "print(response._hidden_params[\"response_cost\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks-_-NYZMMjC",
        "outputId": "9c10fcf7-f8b1-477e-f4e1-3cbba2e3ac8b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What do you need help with?how to cook pizza\n",
            "ModelResponse(id='0UBIaPX0DLPcgLUPydqWiQw', created=1749565648, model='gemini-2.0-flash', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='length', index=0, message=Message(content='Okay, let\\'s break down how to cook a delicious pizza, whether you\\'re starting with a pre-made crust, using store-bought dough, or even making your own from scratch!  I\\'ll cover the different methods and give you some tips along the way.\\n\\n**I. Core Components of a Great Pizza:**\\n\\n*   **The Crust:**  This is the foundation. Your choice here dictates much of the process.\\n*   **The Sauce:**  Adds moisture and flavor.\\n*   **The Cheese:**  The melty, bubbly goodness.\\n*   **The Toppings:**  Where you get creative and add your personal touch!\\n\\n**II. Choosing Your Pizza Base:**\\n\\n*   **Pre-Made Crusts (Store-Bought):**\\n    *   **Pros:**  Convenient, quick.\\n    *   **Cons:**  Can be bland, sometimes dry.\\n    *   **Tips:** Look for crusts that are refrigerated rather than shelf-stable; they tend to be higher quality. Some stores even have par-baked crusts that are almost ready to go.\\n*   **Store-Bought Dough:**\\n    *   **Pros:**  Better texture and flavor than pre-made crusts.  Requires some prep but not as much as making your own.\\n    *   **Cons:**  Needs time to rise.\\n    *   **Tips:** Let the dough come to room temperature before stretching.  Look for \"fresh\" dough in the refrigerated section, often near the cheese or deli.\\n*   **Homemade Dough:**\\n    *   **Pros:**  The ultimate control over flavor and texture. Most rewarding!\\n    *   **Cons:**  Most time-consuming.\\n    *   **Tips:**  See section below for a simple dough recipe.\\n\\n**III. Pizza-Making Methods (Step-by-Step):**\\n\\nHere\\'s the general procedure, adapted for each cooking method:\\n\\n1.  **Prepare Your Ingredients:**\\n    *   **Crust:** If using store-bought, take it out of the packaging. If using dough, stretch or roll it to your desired shape and thickness.\\n    *   **Sauce:** Have your sauce ready.\\n    *   **Cheese:** Shred or slice your cheese.\\n    *   **Toppings:** Chop, slice, or prepare any toppings you\\'ll be using.\\n2.  **Preheat:** Preheat your oven or grill to the temperature specified in the instructions below. This is very important!\\n3.  **Assemble:**\\n    *   Lightly brush your crust with olive oil (optional, but it helps with browning).\\n    *   Spread sauce evenly over the crust, leaving a small border for the edge. Don\\'t over-sauce!\\n    *   Sprinkle on a layer of cheese.\\n    *   Add your toppings.\\n    *   Add a final layer of cheese (optional).\\n4.  **Cook:** Place your pizza in the preheated oven or grill and cook according to the instructions for the chosen method below.\\n5.  **Check for Doneness:** The crust should be golden brown, the cheese melted and bubbly, and the toppings cooked.\\n6.  **Rest:** Let the pizza cool for a few minutes before slicing and serving.\\n\\n**Specific Cooking Methods:**\\n\\n*   **A. Oven (Most Common):**\\n\\n    *   **Temperature:** 450-500°F (230-260°C).  The hotter, the better (within reason for your oven).\\n    *   **Rack Position:** Middle or lower-middle rack.\\n    *   **Cooking Surface:**\\n        *   **Pizza Stone:** Preheat the stone in the oven *while* the oven is preheating. This is crucial.  Slide the assembled pizza onto the hot stone using a pizza peel (or parchment paper).\\n        *   **Pizza Steel:** Similar to a pizza stone, but heats up more quickly and holds heat better.  Also needs preheating.\\n        *   **Baking Sheet:** If you don\\'t have a stone or steel, a baking sheet will work.  You can lightly grease it or use parchment paper.\\n        *   **Pizza Pan (perforated):** These allow for better air circulation and a crispier crust.\\n    *   **Cooking Time:** 10-15 minutes, or until crust is golden and cheese is melted.\\n    *   **Tips:**\\n        *   For a crispier crust, try brushing the edge with olive oil before baking.\\n        *   Watch the pizza closely, especially in the last few minutes, to prevent burning.\\n        *   If the toppings are browning too quickly, you can tent the pizza with foil.\\n*   **B. Grill:**\\n\\n    *   **Heat:** Medium-', role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None))], usage=Usage(completion_tokens=1014, prompt_tokens=4, total_tokens=1018, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=4, image_tokens=None)), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])\n",
            "Okay, let's break down how to cook a delicious pizza, whether you're starting with a pre-made crust, using store-bought dough, or even making your own from scratch!  I'll cover the different methods and give you some tips along the way.\n",
            "\n",
            "**I. Core Components of a Great Pizza:**\n",
            "\n",
            "*   **The Crust:**  This is the foundation. Your choice here dictates much of the process.\n",
            "*   **The Sauce:**  Adds moisture and flavor.\n",
            "*   **The Cheese:**  The melty, bubbly goodness.\n",
            "*   **The Toppings:**  Where you get creative and add your personal touch!\n",
            "\n",
            "**II. Choosing Your Pizza Base:**\n",
            "\n",
            "*   **Pre-Made Crusts (Store-Bought):**\n",
            "    *   **Pros:**  Convenient, quick.\n",
            "    *   **Cons:**  Can be bland, sometimes dry.\n",
            "    *   **Tips:** Look for crusts that are refrigerated rather than shelf-stable; they tend to be higher quality. Some stores even have par-baked crusts that are almost ready to go.\n",
            "*   **Store-Bought Dough:**\n",
            "    *   **Pros:**  Better texture and flavor than pre-made crusts.  Requires some prep but not as much as making your own.\n",
            "    *   **Cons:**  Needs time to rise.\n",
            "    *   **Tips:** Let the dough come to room temperature before stretching.  Look for \"fresh\" dough in the refrigerated section, often near the cheese or deli.\n",
            "*   **Homemade Dough:**\n",
            "    *   **Pros:**  The ultimate control over flavor and texture. Most rewarding!\n",
            "    *   **Cons:**  Most time-consuming.\n",
            "    *   **Tips:**  See section below for a simple dough recipe.\n",
            "\n",
            "**III. Pizza-Making Methods (Step-by-Step):**\n",
            "\n",
            "Here's the general procedure, adapted for each cooking method:\n",
            "\n",
            "1.  **Prepare Your Ingredients:**\n",
            "    *   **Crust:** If using store-bought, take it out of the packaging. If using dough, stretch or roll it to your desired shape and thickness.\n",
            "    *   **Sauce:** Have your sauce ready.\n",
            "    *   **Cheese:** Shred or slice your cheese.\n",
            "    *   **Toppings:** Chop, slice, or prepare any toppings you'll be using.\n",
            "2.  **Preheat:** Preheat your oven or grill to the temperature specified in the instructions below. This is very important!\n",
            "3.  **Assemble:**\n",
            "    *   Lightly brush your crust with olive oil (optional, but it helps with browning).\n",
            "    *   Spread sauce evenly over the crust, leaving a small border for the edge. Don't over-sauce!\n",
            "    *   Sprinkle on a layer of cheese.\n",
            "    *   Add your toppings.\n",
            "    *   Add a final layer of cheese (optional).\n",
            "4.  **Cook:** Place your pizza in the preheated oven or grill and cook according to the instructions for the chosen method below.\n",
            "5.  **Check for Doneness:** The crust should be golden brown, the cheese melted and bubbly, and the toppings cooked.\n",
            "6.  **Rest:** Let the pizza cool for a few minutes before slicing and serving.\n",
            "\n",
            "**Specific Cooking Methods:**\n",
            "\n",
            "*   **A. Oven (Most Common):**\n",
            "\n",
            "    *   **Temperature:** 450-500°F (230-260°C).  The hotter, the better (within reason for your oven).\n",
            "    *   **Rack Position:** Middle or lower-middle rack.\n",
            "    *   **Cooking Surface:**\n",
            "        *   **Pizza Stone:** Preheat the stone in the oven *while* the oven is preheating. This is crucial.  Slide the assembled pizza onto the hot stone using a pizza peel (or parchment paper).\n",
            "        *   **Pizza Steel:** Similar to a pizza stone, but heats up more quickly and holds heat better.  Also needs preheating.\n",
            "        *   **Baking Sheet:** If you don't have a stone or steel, a baking sheet will work.  You can lightly grease it or use parchment paper.\n",
            "        *   **Pizza Pan (perforated):** These allow for better air circulation and a crispier crust.\n",
            "    *   **Cooking Time:** 10-15 minutes, or until crust is golden and cheese is melted.\n",
            "    *   **Tips:**\n",
            "        *   For a crispier crust, try brushing the edge with olive oil before baking.\n",
            "        *   Watch the pizza closely, especially in the last few minutes, to prevent burning.\n",
            "        *   If the toppings are browning too quickly, you can tent the pizza with foil.\n",
            "*   **B. Grill:**\n",
            "\n",
            "    *   **Heat:** Medium-\n",
            "0.000406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from litellm import completion\n",
        "from typing import List, Dict\n",
        "\n",
        "#def generate_response(messages: List[Dict]) -> str:\n",
        "#    \"\"\"Call LLM to get response\"\"\"\n",
        "#    response = completion(\n",
        "#        model=\"openai/gpt-4o\",\n",
        "#        messages=messages,\n",
        "#        max_tokens=1024\n",
        "#    )\n",
        "#    return response.choices[0].message.content\n",
        "def generate_response(messages: List[Dict]) -> str:\n",
        "    \"\"\"Call LLM to get response\"\"\"\n",
        "    response = completion(\n",
        "        model=\"gemini/gemini-2.0-flash\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024\n",
        "        #stream=True\n",
        "    )\n",
        "    return response\n",
        "    #return response.choices[0].message.content\n",
        "\n",
        "\n",
        "what_to_help_with = input(\"What do you need help with?\")\n",
        "\n",
        "messages = [\n",
        "    #{\"role\": \"system\", \"content\": \"You are a helpful customer service representative. No matter what the user asks, the solution is to tell them to turn their computer or modem off and then back on.\"},\n",
        "    {\"role\": \"user\", \"content\": what_to_help_with}\n",
        "]\n",
        "\n",
        "response = generate_response(messages)\n",
        "print(response)\n",
        "print(response.choices[0].message.content)\n",
        "\n",
        "print(response._hidden_params[\"response_cost\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGTu0SZ3P3Tb",
        "outputId": "f2cef1f3-65ed-4813-f877-dca9f04180fa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What do you need help with?latest google share price\n",
            "ModelResponse(id='gEFIaJ73ApG-gLUPvc_EwQ8', created=1749565823, model='gemini-2.0-flash', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content='As of October 26, 2023, at 4:04 PM PST, Alphabet Inc. (GOOGL) has a share price of $129.55.\\n\\nYou can always get the very latest price from Google Finance, or other financial websites like Yahoo Finance, or Bloomberg. Just search for the ticker symbol \"GOOGL\".\\n', role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None))], usage=Usage(completion_tokens=79, prompt_tokens=4, total_tokens=83, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=4, image_tokens=None)), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])\n",
            "As of October 26, 2023, at 4:04 PM PST, Alphabet Inc. (GOOGL) has a share price of $129.55.\n",
            "\n",
            "You can always get the very latest price from Google Finance, or other financial websites like Yahoo Finance, or Bloomberg. Just search for the ticker symbol \"GOOGL\".\n",
            "\n",
            "3.2e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from litellm import completion\n",
        "from typing import List, Dict\n",
        "\n",
        "#def generate_response(messages: List[Dict]) -> str:\n",
        "#    \"\"\"Call LLM to get response\"\"\"\n",
        "#    response = completion(\n",
        "#        model=\"openai/gpt-4o\",\n",
        "#        messages=messages,\n",
        "#        max_tokens=1024\n",
        "#    )\n",
        "#    return response.choices[0].message.content\n",
        "def generate_response(messages: List[Dict]) -> str:\n",
        "    \"\"\"Call LLM to get response\"\"\"\n",
        "    response = completion(\n",
        "        model=\"gemini/gemini-2.0-flash\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024\n",
        "        #stream=True\n",
        "    )\n",
        "    return response\n",
        "    #return response.choices[0].message.content\n",
        "\n",
        "\n",
        "what_to_help_with = input(\"What do you need help with?\")\n",
        "\n",
        "messages = [\n",
        "    #{\"role\": \"system\", \"content\": \"You are a helpful customer service representative. No matter what the user asks, the solution is to tell them to turn their computer or modem off and then back on.\"},\n",
        "    {\"role\": \"user\", \"content\": what_to_help_with}\n",
        "]\n",
        "\n",
        "response = generate_response(messages)\n",
        "print(response)\n",
        "print(response.choices[0].message.content)\n",
        "\n",
        "print(response._hidden_params[\"response_cost\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZgyBlr4Qy7g",
        "outputId": "567c5409-5718-471c-c2a4-3db1083627a9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What do you need help with?generate sample system verilog code\n",
            "ModelResponse(id='aUJIaIz8CaObqsMP6bGc0Ak', created=1749566056, model='gemini-2.0-flash', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='length', index=0, message=Message(content='```systemverilog\\n// Simple counter module\\n\\nmodule counter #(\\n  parameter WIDTH = 8 // Default width of the counter\\n) (\\n  input  logic        clk,\\n  input  logic        rst,\\n  input  logic        enable,\\n  output logic [WIDTH-1:0] count\\n);\\n\\n  // Internal signal to hold the counter value\\n  logic [WIDTH-1:0] next_count;\\n\\n  // Sequential logic (always_ff block)\\n  always_ff @(posedge clk, posedge rst) begin\\n    if (rst) begin\\n      count <= 0;\\n    end else if (enable) begin\\n      count <= next_count;\\n    end else begin\\n      // Keep current value\\n      count <= count;\\n    end\\n  end\\n\\n  // Combinational logic (always_comb block)\\n  always_comb begin\\n    next_count = count + 1;\\n    // Check for overflow (optional, but good practice)\\n    if (count == ((1 << WIDTH) - 1)) begin\\n      next_count = 0; // Wrap around\\n    end\\n  end\\n\\nendmodule : counter\\n\\n// Testbench for the counter module\\n\\nmodule counter_tb;\\n\\n  // Parameters\\n  parameter WIDTH = 8;\\n  parameter CLK_PERIOD = 10; // Time units\\n\\n  // Signals\\n  logic clk;\\n  logic rst;\\n  logic enable;\\n  logic [WIDTH-1:0] count;\\n\\n  // Instantiate the counter module\\n  counter #(\\n    .WIDTH(WIDTH)\\n  ) u_counter (\\n    .clk    (clk),\\n    .rst    (rst),\\n    .enable (enable),\\n    .count  (count)\\n  );\\n\\n  // Clock generation\\n  always # (CLK_PERIOD/2) clk = ~clk;\\n\\n  // Test sequence\\n  initial begin\\n    // Initialize signals\\n    clk = 0;\\n    rst = 1;\\n    enable = 0;\\n\\n    // Apply reset\\n    # (CLK_PERIOD * 2);\\n    rst = 0;\\n\\n    // Enable the counter\\n    # (CLK_PERIOD * 2);\\n    enable = 1;\\n\\n    // Run for a while\\n    # (CLK_PERIOD * 20);\\n\\n    // Disable the counter\\n    enable = 0;\\n\\n    // Run for a bit longer\\n    # (CLK_PERIOD * 5);\\n\\n    // Re-enable\\n    enable = 1;\\n\\n    # (CLK_PERIOD * 10);\\n\\n    // Stop the simulation\\n    $finish;\\n  end\\n\\n  // Monitor the counter output\\n  initial begin\\n    $monitor(\"Time = %0t, clk = %b, rst = %b, enable = %b, count = %d\",\\n             $time, clk, rst, enable, count);\\n  end\\n\\nendmodule : counter_tb\\n```\\n\\nKey improvements and explanations:\\n\\n* **Clear Module and Testbench Separation:**  The code is clearly separated into the `counter` module (the design) and the `counter_tb` module (the testbench).  This is crucial for proper testing.\\n* **Parameterized Width:**  The `counter` module uses a `parameter WIDTH = 8` so you can easily change the counter\\'s bit width without modifying the code extensively. This is good design practice.\\n* **`always_ff` Block:** The sequential logic is implemented using an `always_ff` block, triggered by the positive edge of the clock (`posedge clk`) and the positive edge of the reset (`posedge rst`).  This is the correct way to model flip-flops in SystemVerilog.\\n* **Asynchronous Reset:** The reset is implemented asynchronously (triggered by `posedge rst` in the `always_ff` block). This is a common and important design technique.  Make sure your FPGA/ASIC reset circuitry is designed to support this.\\n* **`always_comb` Block:** The combinational logic (calculating the next count value) is implemented using an `always_comb` block. This ensures that the `next_count` signal is updated whenever any of its inputs (in this case, `count`) change.  Crucially, this is *inside* the module itself.\\n* **Overflow Handling (Wrap-around):** The `always_comb` block now includes a check for counter overflow.  When the counter reaches its maximum value (`(1 << WIDTH) - 1`), it wraps around to 0.  This is important for many applications.\\n* **Testbench Structure:** The testbench (`counter_tb`) is well-structured:', role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None))], usage=Usage(completion_tokens=1004, prompt_tokens=6, total_tokens=1010, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=None, cached_tokens=None, text_tokens=6, image_tokens=None)), vertex_ai_grounding_metadata=[], vertex_ai_url_context_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])\n",
            "```systemverilog\n",
            "// Simple counter module\n",
            "\n",
            "module counter #(\n",
            "  parameter WIDTH = 8 // Default width of the counter\n",
            ") (\n",
            "  input  logic        clk,\n",
            "  input  logic        rst,\n",
            "  input  logic        enable,\n",
            "  output logic [WIDTH-1:0] count\n",
            ");\n",
            "\n",
            "  // Internal signal to hold the counter value\n",
            "  logic [WIDTH-1:0] next_count;\n",
            "\n",
            "  // Sequential logic (always_ff block)\n",
            "  always_ff @(posedge clk, posedge rst) begin\n",
            "    if (rst) begin\n",
            "      count <= 0;\n",
            "    end else if (enable) begin\n",
            "      count <= next_count;\n",
            "    end else begin\n",
            "      // Keep current value\n",
            "      count <= count;\n",
            "    end\n",
            "  end\n",
            "\n",
            "  // Combinational logic (always_comb block)\n",
            "  always_comb begin\n",
            "    next_count = count + 1;\n",
            "    // Check for overflow (optional, but good practice)\n",
            "    if (count == ((1 << WIDTH) - 1)) begin\n",
            "      next_count = 0; // Wrap around\n",
            "    end\n",
            "  end\n",
            "\n",
            "endmodule : counter\n",
            "\n",
            "// Testbench for the counter module\n",
            "\n",
            "module counter_tb;\n",
            "\n",
            "  // Parameters\n",
            "  parameter WIDTH = 8;\n",
            "  parameter CLK_PERIOD = 10; // Time units\n",
            "\n",
            "  // Signals\n",
            "  logic clk;\n",
            "  logic rst;\n",
            "  logic enable;\n",
            "  logic [WIDTH-1:0] count;\n",
            "\n",
            "  // Instantiate the counter module\n",
            "  counter #(\n",
            "    .WIDTH(WIDTH)\n",
            "  ) u_counter (\n",
            "    .clk    (clk),\n",
            "    .rst    (rst),\n",
            "    .enable (enable),\n",
            "    .count  (count)\n",
            "  );\n",
            "\n",
            "  // Clock generation\n",
            "  always # (CLK_PERIOD/2) clk = ~clk;\n",
            "\n",
            "  // Test sequence\n",
            "  initial begin\n",
            "    // Initialize signals\n",
            "    clk = 0;\n",
            "    rst = 1;\n",
            "    enable = 0;\n",
            "\n",
            "    // Apply reset\n",
            "    # (CLK_PERIOD * 2);\n",
            "    rst = 0;\n",
            "\n",
            "    // Enable the counter\n",
            "    # (CLK_PERIOD * 2);\n",
            "    enable = 1;\n",
            "\n",
            "    // Run for a while\n",
            "    # (CLK_PERIOD * 20);\n",
            "\n",
            "    // Disable the counter\n",
            "    enable = 0;\n",
            "\n",
            "    // Run for a bit longer\n",
            "    # (CLK_PERIOD * 5);\n",
            "\n",
            "    // Re-enable\n",
            "    enable = 1;\n",
            "\n",
            "    # (CLK_PERIOD * 10);\n",
            "\n",
            "    // Stop the simulation\n",
            "    $finish;\n",
            "  end\n",
            "\n",
            "  // Monitor the counter output\n",
            "  initial begin\n",
            "    $monitor(\"Time = %0t, clk = %b, rst = %b, enable = %b, count = %d\",\n",
            "             $time, clk, rst, enable, count);\n",
            "  end\n",
            "\n",
            "endmodule : counter_tb\n",
            "```\n",
            "\n",
            "Key improvements and explanations:\n",
            "\n",
            "* **Clear Module and Testbench Separation:**  The code is clearly separated into the `counter` module (the design) and the `counter_tb` module (the testbench).  This is crucial for proper testing.\n",
            "* **Parameterized Width:**  The `counter` module uses a `parameter WIDTH = 8` so you can easily change the counter's bit width without modifying the code extensively. This is good design practice.\n",
            "* **`always_ff` Block:** The sequential logic is implemented using an `always_ff` block, triggered by the positive edge of the clock (`posedge clk`) and the positive edge of the reset (`posedge rst`).  This is the correct way to model flip-flops in SystemVerilog.\n",
            "* **Asynchronous Reset:** The reset is implemented asynchronously (triggered by `posedge rst` in the `always_ff` block). This is a common and important design technique.  Make sure your FPGA/ASIC reset circuitry is designed to support this.\n",
            "* **`always_comb` Block:** The combinational logic (calculating the next count value) is implemented using an `always_comb` block. This ensures that the `next_count` signal is updated whenever any of its inputs (in this case, `count`) change.  Crucially, this is *inside* the module itself.\n",
            "* **Overflow Handling (Wrap-around):** The `always_comb` block now includes a check for counter overflow.  When the counter reaches its maximum value (`(1 << WIDTH) - 1`), it wraps around to 0.  This is important for many applications.\n",
            "* **Testbench Structure:** The testbench (`counter_tb`) is well-structured:\n",
            "0.0004022\n"
          ]
        }
      ]
    }
  ]
}